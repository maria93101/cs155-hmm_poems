{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from HMM import supervised_HMM, unsupervised_HMM, HiddenMarkovModel\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_poems(filename):\n",
    "    \n",
    "    lines = [] # 2d dictionary, each array is a split + cleaned line\n",
    "    words = {} # dictionary of a word, and its frequency\n",
    "    \n",
    "    file = open(filename, 'r')\n",
    "    \n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if  len(line) < 10:\n",
    "            # Too short to be a valid line\n",
    "            continue\n",
    "        line = \"\".join(l for l in line if l not in string.punctuation)\n",
    "        line = line.lower()\n",
    "        line = line.split()\n",
    "        \n",
    "        lines.append(line)\n",
    "\n",
    "        for word in line:\n",
    "            try:\n",
    "                # add to frequency if the word is already in the dic\n",
    "                words[word] += 1\n",
    "            except KeyError:\n",
    "                # if not, add the word to the dic\n",
    "                words[word] = 1\n",
    "    return lines, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/shakespeare.txt\"\n",
    "lines, words = load_poems(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['from', 'fairest', 'creatures', 'we', 'desire', 'increase']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_learning(lines, n_states, n_iters):\n",
    "    '''\n",
    "    n_iters: Number of iterations we should go through.\n",
    "    n_states: Number of hidden states our HMM should have.\n",
    "    '''\n",
    "    # Train the HMM.\n",
    "    obs, obs_map =  parse_observations(lines)\n",
    "    flat_lines = [[item] for sublist in lines for item in sublist]\n",
    "    leHMM = unsupervised_HMM(obs, n_states, n_iters)\n",
    "    return leHMM, obs,obs_map \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_map_reverser(obs_map):\n",
    "    obs_map_r = {}\n",
    "\n",
    "    for key in obs_map:\n",
    "        obs_map_r[obs_map[key]] = key\n",
    "\n",
    "    return obs_map_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_observations(lines):\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "\n",
    "    for line in lines:\n",
    "        obs_elem = []\n",
    "\n",
    "        for word in line:\n",
    "            word = re.sub(r'[^\\w]', '', word).lower()\n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "\n",
    "            # Add the encoded word.\n",
    "            obs_elem.append(obs_map[word])\n",
    "\n",
    "        # Add the encoded sequence.\n",
    "        obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, obs_map = parse_observations(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get syllable info from syllable_dictionary.txt\n",
    "def load_syllables(filename):\n",
    "    file = open(filename, 'r')\n",
    "    syllable = {}\n",
    "    for line in file:\n",
    "        line = line.split()\n",
    "        #print(line)\n",
    "        word = line[0]\n",
    "        rest = line[1: len(line)]\n",
    "\n",
    "        syllable[word] = rest\n",
    "    return syllable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/Syllable_dictionary.txt\"\n",
    "syllable = load_syllables(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_HMM(hmmmmmm, filename):\n",
    "    \n",
    "    with open(filename+\".txt\", \"w+\") as filept:\n",
    "        filept.write(str(hmmmmmm.L)+\"\\n\")\n",
    "        filept.write(str(hmmmmmm.D)+\"\\n\")\n",
    "        for i in hmmmmmm.A:\n",
    "            line = \"\"\n",
    "            for j in i:\n",
    "                line += str(j) + \",\"\n",
    "            filept.write(line[:len(line)-1]+\"\\n\")\n",
    "        for i in hmmmmmm.O:\n",
    "            line = \"\"\n",
    "            for j in i:\n",
    "                line += str(j) + \",\"\n",
    "            filept.write(line[:len(line)-1]+\"\\n\")\n",
    "        \n",
    "\n",
    "def read_HMM(filename):\n",
    "    with open(filename+\".txt\", \"r\") as filept:\n",
    "        L = int(filept.readline())\n",
    "        D = int(filept.readline())\n",
    "        O = []\n",
    "        A = []\n",
    "        for i in range(L):\n",
    "            line = [float(x) for x in filept.readline().split(\",\")]\n",
    "            A.append(line)\n",
    "        for j in range(L):\n",
    "            line = [float(x) for x in filept.readline().split(\",\")]\n",
    "            O.append(line)\n",
    "    return HiddenMarkovModel(A, O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testHMM40 = read_HMM(\"40-iter-8-hidden-hmm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_map_r = obs_map_reverser(obs_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summers as be oer love thine not lilys doth lie\n",
      "Better composition prove write self have best in potions into\n",
      "Light and on thee longing live will physic good works\n",
      "Centre if thee sepulchres and truths make i for now\n",
      "Oer see and blunter give of thine correct to eager\n",
      "So was eithers thine youth most a like can wrong\n",
      "Thy beguiled show be than still thee makes all where\n",
      "I eye i durst thing this in perfect others calls\n",
      "Not times all on delight lack to out the hate\n",
      "Tomb and to the summers who strong and to on\n",
      "Intents may this greater but time bars seeting by by\n",
      "Mens most in is sense defendant more as flesh do\n",
      "Good were illused how like go is key true foot\n",
      "Discased still where every the distance invoked silent shake loves\n"
     ]
    }
   ],
   "source": [
    "for i in range(14): # each poem is 14 lines long\n",
    "    emission = testHMM40.generate_emission(10) # each line is 10 words long\n",
    "    sentence = [obs_map_r[i] for i in emission[0]]\n",
    "\n",
    "    print(' '.join(sentence).capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Belied so by after the and more lords\n",
      "Be please fair knew worst thou show is to with\n",
      "Worthy of then fearing these thy verse muse\n",
      "That heaven of kindness you of breast thy have\n",
      "But authority this man i part so\n",
      "Hath pluck let but dost a is to and and\n",
      "World friends word continual tyrant that hide\n",
      "Heart shallowest so and the by watchman so\n",
      "The a say so at pride or policy\n",
      "When nor me i for by they my my he\n",
      "Writ for burn of thy have with make of thy\n",
      "War remover to my time show and your\n",
      "Than spoil so of advantage every but\n",
      "Must thy you palate she thy yet you she\n"
     ]
    }
   ],
   "source": [
    "for i in range(14): # each poem is 14 lines long\n",
    "    emission = testHMM40.generate_emission_syllables(10, obs_map_r, syllable) # each line is 10 words long\n",
    "    sentence = [obs_map_r[i] for i in emission[0]]\n",
    "\n",
    "    print(' '.join(sentence).capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These and wit speed love so they ride due praise\n",
      "Do the world not one a in lovers is\n",
      "My love and i use through report my it\n",
      "These thee her this abundance as and large\n",
      "Action thee love vows rhymers long worth can\n",
      "Thee woos down speak evermore sauces went\n",
      "So found i sun crossed is of as odours\n",
      "Folly away mine their thy heart thy all\n",
      "Merchandized call any saw issue chide\n",
      "Stay bosoms bright take is changing judgement\n",
      "Another figure my in thy at to\n",
      "Or where sinful these unlearned rest on\n",
      "The upon my catch thee pity name shall\n",
      "To now live taste heavy that the watchman\n"
     ]
    }
   ],
   "source": [
    "for i in range(14): # each poem is 14 lines long\n",
    "    emission = testHMM40.generate_emission_syllables_other(10, obs_map_r, syllable) # each line is 10 words long\n",
    "    sentence = [obs_map_r[i] for i in emission[0]]\n",
    "\n",
    "    print(' '.join(sentence).capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Those in i those are hindmost on stay seem\n",
      "Stores my blame thy bloody thy is my it\n",
      "To they is stones did him is give of flower\n",
      "Self registers missed rhyme my birth as when\n",
      "Hate your vassal doth siren thy thine earth\n",
      "Art where rest your wound my home better of\n",
      "Feathered them a like truest power their are\n",
      "At thy thou and the mountain palate thy\n",
      "On but unless that gives reeleth quite thy\n",
      "To my impute towers for i appetite\n",
      "O hours so then idle feeds way and bare\n",
      "Boast and do me old tired the low so east\n",
      "Beated woeful breast and thine her of thy\n",
      "Graces and i should then those you shine me\n"
     ]
    }
   ],
   "source": [
    "for i in range(14): # each poem is 14 lines long\n",
    "    emission = testHMM40.generate_emission_syllables_correct(10, obs_map_r, syllable) # each line is 10 words long\n",
    "    sentence = [obs_map_r[i] for i in emission[0]]\n",
    "\n",
    "    print(' '.join(sentence).capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def script():\n",
    "    file = open(\"data/shakespeare.txt\", 'r')\n",
    "    throwaway = [98, 125, 144]\n",
    "    sonnet_counter = 0\n",
    "    i = 0\n",
    "    all_pairs = []\n",
    "    temp = [[] for _ in range(7)]\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if len(line) < 10:\n",
    "            # Too short to be a valid line\n",
    "            if i != 0:\n",
    "                if sonnet_counter not in throwaway:\n",
    "                    all_pairs.extend(temp)\n",
    "                sonnet_counter += 1\n",
    "                i = 0\n",
    "                temp = [[] for _ in range(7)]\n",
    "            continue\n",
    "        line = \"\".join(l for l in line if l not in string.punctuation)\n",
    "        line = line.lower()\n",
    "        line = line.split()\n",
    "        \n",
    "        last = line[-1]\n",
    "        \n",
    "        if i == 0 or i == 2:\n",
    "            # a\n",
    "            temp[0].append(last)\n",
    "        elif i == 1 or i == 3:\n",
    "            #b\n",
    "            temp[1].append(last)\n",
    "        elif i==4 or i==6:\n",
    "            #c\n",
    "            temp[2].append(last)\n",
    "        elif i==5 or i==7:\n",
    "            #d\n",
    "            temp[3].append(last)\n",
    "            \n",
    "        elif i==8 or i==10:\n",
    "            #e\n",
    "            temp[4].append(last)\n",
    "            \n",
    "        elif i==9 or i==11:\n",
    "            #f\n",
    "            temp[5].append(last)\n",
    "            \n",
    "        elif i==12 or i==13:\n",
    "            #g\n",
    "            temp[6].append(last)\n",
    "            \n",
    "        i += 1\n",
    "        lines.append(line)\n",
    "\n",
    "                \n",
    "    all_pairs_dict = {}\n",
    "    for i, j in all_pairs:\n",
    "        if i not in all_pairs_dict:\n",
    "                    all_pairs_dict[i] = [j]\n",
    "                \n",
    "        if j not in all_pairs_dict:\n",
    "                    all_pairs_dict[j] = [i]\n",
    "                \n",
    "        # checking all against all other pairs\n",
    "        for k in all_pairs:\n",
    "            # If i or j is in k, this means we need to add things\n",
    "            if i in k or j in k:\n",
    "                for a in k:\n",
    "                    if a not in all_pairs_dict[i] and a != i:\n",
    "                        all_pairs_dict[i].append(a)\n",
    "                    if a not in all_pairs_dict[j] and a != j:\n",
    "                        all_pairs_dict[j].append(a)\n",
    "           \n",
    "    # Completing the graph. \n",
    "    for key, val in all_pairs_dict.items():\n",
    "        for i in val:\n",
    "            if key not in all_pairs_dict[i]:\n",
    "                all_pairs_dict[i].append(key)\n",
    "            for j in val:\n",
    "                if j != i and j not in all_pairs_dict[i]:\n",
    "                    all_pairs_dict[i].append(j)\n",
    "                    \n",
    "    return all_pairs, all_pairs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs, all_pairs_dict  = script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 3175 8 8\n",
      "208\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-ab8f91732525>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_pairs_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mword2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0memission1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestHMM40\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_emission_rhyme\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs_map_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# each line is 10 words long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0memission2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestHMM40\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_emission_rhyme\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs_map_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0msentence1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mobs_map_r\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0memission1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\CS155\\project3\\cs155-hmm_poems\\HMM.py\u001b[0m in \u001b[0;36mgenerate_emission_rhyme\u001b[1;34m(self, M, obs_map_r, rhyme)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mrand_var\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m             \u001b[0mrand_var\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mO\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurr_state\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrhyme\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m             \u001b[0mcurr_state\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(7): # each poem is 14 lines long, with 7 rhymes\n",
    "    word = np.random.choice(list(all_pairs_dict.keys()))\n",
    "    words = all_pairs_dict[word]\n",
    "    word2 = np.random.choice(words)\n",
    "    emission1 = testHMM40.generate_emission_rhyme(10, obs_map_r, obs_map[word]) # each line is 10 words long\n",
    "    emission2 = testHMM40.generate_emission_rhyme(10, obs_map_r, obs_map[word2])\n",
    "    sentence1 = [obs_map_r[i] for i in emission1[0]]\n",
    "    sentence2 = [obs_map_r[i] for i in emission2[0]]\n",
    "\n",
    "    print(' '.join(sentence1).capitalize())\n",
    "    print(' '.join(sentence2).capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = np.random.choice(list(all_pairs_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_map[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
