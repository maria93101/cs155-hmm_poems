{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import string\n",
    "from HMM import supervised_HMM, unsupervised_HMM, HiddenMarkovModel\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_observations(lines):\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "\n",
    "    for line in lines:\n",
    "        obs_elem = []\n",
    "\n",
    "        for word in line:\n",
    "            word = re.sub(r'[^\\w]', '', word).lower()\n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "\n",
    "            # Add the encoded word.\n",
    "            obs_elem.append(obs_map[word])\n",
    "\n",
    "        # Add the encoded sequence.\n",
    "        obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_learning(lines, n_states, n_iters):\n",
    "    '''\n",
    "    n_iters: Number of iterations we should go through.\n",
    "    n_states: Number of hidden states our HMM should have.\n",
    "    '''\n",
    "    # Train the HMM.\n",
    "    obs, obs_map =  parse_observations(lines)\n",
    "    flat_lines = [[item] for sublist in lines for item in sublist]\n",
    "    leHMM = unsupervised_HMM(obs, n_states, n_iters)\n",
    "    return leHMM, obs,obs_map \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_poems(files):\n",
    "    \n",
    "    lines = [] # 2d dictionary, each array is a split + cleaned line\n",
    "    words = {} # dictionary of a word, and its frequency\n",
    "    \n",
    "    for f in files:\n",
    "        file = open(f, 'r')\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if  len(line) < 10:\n",
    "                # Too short to be a valid line\n",
    "                continue\n",
    "            line = \"\".join(l for l in line if l not in string.punctuation)\n",
    "            line = line.lower()\n",
    "            line = line.split()\n",
    "\n",
    "            lines.append(line)\n",
    "\n",
    "            for word in line:\n",
    "                try:\n",
    "                    # add to frequency if the word is already in the dic\n",
    "                    words[word] += 1\n",
    "                except KeyError:\n",
    "                    # if not, add the word to the dic\n",
    "                    words[word] = 1\n",
    "    return lines, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_HMM(hmmmmmm, filename):\n",
    "    \n",
    "    with open(filename+\".txt\", \"w+\") as filept:\n",
    "        filept.write(str(hmmmmmm.L)+\"\\n\")\n",
    "        filept.write(str(hmmmmmm.D)+\"\\n\")\n",
    "        for i in hmmmmmm.A:\n",
    "            line = \"\"\n",
    "            for j in i:\n",
    "                line += str(j) + \",\"\n",
    "            filept.write(line[:len(line)-1]+\"\\n\")\n",
    "        for i in hmmmmmm.O:\n",
    "            line = \"\"\n",
    "            for j in i:\n",
    "                line += str(j) + \",\"\n",
    "            filept.write(line[:len(line)-1]+\"\\n\")\n",
    "        \n",
    "\n",
    "def read_HMM(filename):\n",
    "    with open(filename+\".txt\", \"r\") as filept:\n",
    "        L = int(filept.readline())\n",
    "        D = int(filept.readline())\n",
    "        O = []\n",
    "        A = []\n",
    "        for i in range(L):\n",
    "            line = [float(x) for x in filept.readline().split(\",\")]\n",
    "            A.append(line)\n",
    "        for j in range(L):\n",
    "            line = [float(x) for x in filept.readline().split(\",\")]\n",
    "            O.append(line)\n",
    "    return HiddenMarkovModel(A, O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/shakespeare.txt\"\n",
    "file2 = \"data/spenser.txt\"\n",
    "lines, words = load_poems([file, file2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merp 0\n",
      "merp 1\n",
      "merp 2\n",
      "merp 3\n",
      "merp 4\n",
      "merp 5\n",
      "merp 6\n",
      "merp 7\n",
      "merp 8\n",
      "merp 9\n"
     ]
    }
   ],
   "source": [
    "HMM = unsupervised_learning(lines, 4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'L'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-895ca0661a20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_HMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHMM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"10-iter-4-hidden-hmm-additional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-9fdd938a0ebf>\u001b[0m in \u001b[0;36msave_HMM\u001b[0;34m(hmmmmmm, filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfilept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mfilept\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhmmmmmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mfilept\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhmmmmmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhmmmmmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'L'"
     ]
    }
   ],
   "source": [
    "save_HMM(HMM, \"10-iter-4-hidden-hmm-additional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stress(all_words):\n",
    "    stress = nltk.corpus.cmudict.dict()\n",
    "    stress_dict = {}\n",
    "    unclear = []\n",
    "\n",
    "\n",
    "    for word in all_words:\n",
    "        if word not in stress.keys():\n",
    "            unclear.append(word)\n",
    "        else:\n",
    "            stress_dict[word] = stress[word]\n",
    "\n",
    "    for word in stress_dict.keys():\n",
    "        phoneme = stress_dict[word][0]\n",
    "        syls = []\n",
    "\n",
    "        for phon in phoneme:\n",
    "            if '0' in phon:\n",
    "                syls.append(0)\n",
    "            elif '1' in phon:\n",
    "                syls.append(1)\n",
    "\n",
    "        stress_dict[word] = syls\n",
    "\n",
    "    return stress_dict, unclear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = list(words.keys())\n",
    "# for the stress, just use the first thing from the array\n",
    "stress_dict, unclear = load_stress(all_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
