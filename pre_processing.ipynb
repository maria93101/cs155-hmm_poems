{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from HMM import unsupervised_HMM\n",
    "from nltk.corpus import cmudict\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import RNN\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "import HMM_helper \n",
    "import re\n",
    "\n",
    "# nltk.download() uncomment first time you run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_poems(filename):\n",
    "    \n",
    "    lines = [] # 2d dictionary, each array is a split + cleaned line\n",
    "    words = {} # dictionary of a word, and its frequency\n",
    "    \n",
    "    file = open(filename, 'r')\n",
    "    \n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if  len(line) < 10:\n",
    "            # Too short to be a valid line\n",
    "            continue\n",
    "        line = \"\".join(l for l in line if l not in string.punctuation)\n",
    "        line = line.lower()\n",
    "        line = line.split()\n",
    "        \n",
    "        lines.append(line)\n",
    "\n",
    "        for word in line:\n",
    "            try:\n",
    "                # add to frequency if the word is already in the dic\n",
    "                words[word] += 1\n",
    "            except KeyError:\n",
    "                # if not, add the word to the dic\n",
    "                words[word] = 1\n",
    "    return lines, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/shakespeare.txt\"\n",
    "lines, words = load_poems(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get syllable info from syllable_dictionary.txt\n",
    "def load_syllables(filename):\n",
    "    file = open(filename, 'r')\n",
    "    syllable = {}\n",
    "    for line in file:\n",
    "        line = line.split()\n",
    "        #print(line)\n",
    "        word = line[0]\n",
    "        rest = line[1: len(line)]\n",
    "\n",
    "        syllable[word] = rest\n",
    "    return syllable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-52-d8c6bcb29637>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-52-d8c6bcb29637>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    stresses[word] =\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def load_stresses():\n",
    "    stresses = {}\n",
    "    cmu_stress = cmudict.dict()\n",
    "    for word in cmu_stress.keys():\n",
    "        stresses[word] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_stresses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-adf12f56fc33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/Syllable_dictionary.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msyllable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_syllables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstresses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_stresses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'load_stresses' is not defined"
     ]
    }
   ],
   "source": [
    "filename = \"data/Syllable_dictionary.txt\"\n",
    "syllable = load_syllables(filename)\n",
    "stresses = load_stresses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_observations(lines):\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "\n",
    "    for line in lines:\n",
    "        obs_elem = []\n",
    "\n",
    "        for word in line:\n",
    "            word = re.sub(r'[^\\w]', '', word).lower()\n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "\n",
    "            # Add the encoded word.\n",
    "            obs_elem.append(obs_map[word])\n",
    "\n",
    "        # Add the encoded sequence.\n",
    "        obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map\n",
    "\n",
    "file = \"data/shakespeare.txt\"\n",
    "lines, words = load_poems(file)\n",
    "obs, obs_map = parse_observations(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_learning(lines, n_states, n_iters):\n",
    "    '''\n",
    "    n_iters: Number of iterations we should go through.\n",
    "    n_states: Number of hidden states our HMM should have.\n",
    "    '''\n",
    "    # Train the HMM.\n",
    "    obs, obs_map =  parse_observations(lines)\n",
    "    flat_lines = [[item] for sublist in lines for item in sublist]\n",
    "    HMM = unsupervised_HMM(obs, n_states, n_iters)\n",
    "    return HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'observations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-083363a6ea39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mHMM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munsupervised_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-c5cf1af441aa>\u001b[0m in \u001b[0;36munsupervised_learning\u001b[0;34m(lines, n_states, n_iters)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_map\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mparse_observations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mflat_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mHMM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munsupervised_HMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mHMM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CS155/projects/hmm_poems/HMM.py\u001b[0m in \u001b[0;36munsupervised_HMM\u001b[0;34m(X, n_states, N_iters)\u001b[0m\n",
      "\u001b[0;32m~/CS155/projects/hmm_poems/HMM.py\u001b[0m in \u001b[0;36munsupervised_learning\u001b[0;34m(self, X, iters)\u001b[0m\n\u001b[1;32m    344\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                     \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'observations' is not defined"
     ]
    }
   ],
   "source": [
    "HMM = unsupervised_learning(lines, 4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
